{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfrs_tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnSRTIl5YoQ5"
      },
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAGdMjWJZI-D"
      },
      "source": [
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_2bOUkRZP1g"
      },
      "source": [
        "# Ratings data.\n",
        "ratings = tfds.load('movielens/100k-ratings', split=\"train\")\n",
        "# Features of all the available movies.\n",
        "movies = tfds.load('movielens/100k-movies', split=\"train\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0PL4X-4Zee6"
      },
      "source": [
        "# Select the basic features.\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"]\n",
        "})\n",
        "movies = movies.map(lambda x: x[\"movie_title\"])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K20KRY8KhkW8",
        "outputId": "36520be1-3787-4867-9a38-01c8a5c50c24"
      },
      "source": [
        "# ratings\n",
        "cnt = 0\n",
        "for i in ratings:\n",
        "    if cnt != 10:\n",
        "        print(i)\n",
        "        cnt +=1\n",
        "    else:\n",
        "        break"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b\"One Flew Over the Cuckoo's Nest (1975)\">, 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'138'>}\n",
            "{'movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Strictly Ballroom (1992)'>, 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'92'>}\n",
            "{'movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Very Brady Sequel, A (1996)'>, 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'301'>}\n",
            "{'movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Pulp Fiction (1994)'>, 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'60'>}\n",
            "{'movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Scream 2 (1997)'>, 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'197'>}\n",
            "{'movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Crash (1996)'>, 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'601'>}\n",
            "{'movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Aladdin (1992)'>, 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'710'>}\n",
            "{'movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b'True Romance (1993)'>, 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'833'>}\n",
            "{'movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Bob Roberts (1992)'>, 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'916'>}\n",
            "{'movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Starship Troopers (1997)'>, 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'940'>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5ZSQSjOhOOP",
        "outputId": "320456ab-ae5e-43c6-f2a2-fde8355f2e66"
      },
      "source": [
        "# movies\n",
        "cnt = 0\n",
        "for i in movies:\n",
        "    if cnt != 10:\n",
        "        print(i)\n",
        "        cnt +=1\n",
        "    else:\n",
        "        break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'You So Crazy (1994)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Love Is All There Is (1996)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Fly Away Home (1996)', shape=(), dtype=string)\n",
            "tf.Tensor(b'In the Line of Duty 2 (1987)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Niagara, Niagara (1997)', shape=(), dtype=string)\n",
            "tf.Tensor(b\"Young Poisoner's Handbook, The (1995)\", shape=(), dtype=string)\n",
            "tf.Tensor(b'Age of Innocence, The (1993)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Flirt (1995)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Frisk (1995)', shape=(), dtype=string)\n",
            "tf.Tensor(b'unknown', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lawkCiJ0cD6n",
        "outputId": "8c622b5e-1c5c-4087-ce40-9b30e8582dd1"
      },
      "source": [
        "user_ids_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(mask_token=None)\n",
        "user_ids_vocabulary.adapt(ratings.map(lambda x: x[\"user_id\"]))\n",
        "print(user_ids_vocabulary.get_vocabulary()[0:10])\n",
        "\n",
        "movie_titles_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(mask_token=None)\n",
        "movie_titles_vocabulary.adapt(movies)\n",
        "print(movie_titles_vocabulary.get_vocabulary()[0:10])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[UNK]', '405', '655', '13', '450', '276', '416', '537', '303', '234']\n",
            "['[UNK]', \"Ulee's Gold (1997)\", 'That Darn Cat! (1997)', 'Substance of Fire, The (1996)', 'Sliding Doors (1998)', 'Nightwatch (1997)', 'Money Talks (1997)', 'Kull the Conqueror (1997)', 'Ice Storm, The (1997)', 'Hurricane Streets (1998)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOCKPMTDcx3O"
      },
      "source": [
        "class MovieLensModel(tfrs.Model):\n",
        "  # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
        "  # these are still plain Keras Models.\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      user_model: tf.keras.Model,\n",
        "      movie_model: tf.keras.Model,\n",
        "      task: tfrs.tasks.Retrieval):\n",
        "    super().__init__()\n",
        "\n",
        "    # Set up user and movie representations.\n",
        "    self.user_model = user_model\n",
        "    self.movie_model = movie_model\n",
        "\n",
        "    # Set up a retrieval task.\n",
        "    self.task = task\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    # Define how the loss is computed.\n",
        "\n",
        "    user_embeddings = self.user_model(features[\"user_id\"])\n",
        "    movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
        "\n",
        "    return self.task(user_embeddings, movie_embeddings)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnrtEzdmdFol"
      },
      "source": [
        "# Define user and movie models.\n",
        "user_model = tf.keras.Sequential([\n",
        "    user_ids_vocabulary,\n",
        "    tf.keras.layers.Embedding(user_ids_vocabulary.vocab_size(), 64)\n",
        "])\n",
        "movie_model = tf.keras.Sequential([\n",
        "    movie_titles_vocabulary,\n",
        "    tf.keras.layers.Embedding(movie_titles_vocabulary.vocab_size(), 64)\n",
        "])\n",
        "\n",
        "# Define your objectives.\n",
        "task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
        "    movies.batch(128).map(movie_model)\n",
        "  )\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD2msi8Ej4kl",
        "outputId": "fc4b3af5-e022-4e5a-fabc-8e091371c3a8"
      },
      "source": [
        "# Create a retrieval model.\n",
        "model = MovieLensModel(user_model, movie_model, task)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
        "\n",
        "# Train for 3 epochs.\n",
        "model.fit(ratings.batch(4096), epochs=3)\n",
        "\n",
        "# Use brute-force search to set up retrieval using the trained representations.\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "index.index(movies.batch(100).map(model.movie_model), movies)\n",
        "\n",
        "# Get some recommendations.\n",
        "_, titles = index(np.array([\"42\"]))\n",
        "print(f\"Top 3 recommendations for user 42: {titles[0, :3]}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 14s 553ms/step - factorized_top_k/top_1_categorical_accuracy: 7.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0014 - factorized_top_k/top_10_categorical_accuracy: 0.0046 - factorized_top_k/top_50_categorical_accuracy: 0.0433 - factorized_top_k/top_100_categorical_accuracy: 0.0981 - loss: 33076.6864 - regularization_loss: 0.0000e+00 - total_loss: 33076.6864\n",
            "Epoch 2/3\n",
            "25/25 [==============================] - 14s 556ms/step - factorized_top_k/top_1_categorical_accuracy: 1.7000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0049 - factorized_top_k/top_10_categorical_accuracy: 0.0142 - factorized_top_k/top_50_categorical_accuracy: 0.1047 - factorized_top_k/top_100_categorical_accuracy: 0.2109 - loss: 31011.7233 - regularization_loss: 0.0000e+00 - total_loss: 31011.7233\n",
            "Epoch 3/3\n",
            "25/25 [==============================] - 14s 558ms/step - factorized_top_k/top_1_categorical_accuracy: 3.7000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0082 - factorized_top_k/top_10_categorical_accuracy: 0.0221 - factorized_top_k/top_50_categorical_accuracy: 0.1441 - factorized_top_k/top_100_categorical_accuracy: 0.2689 - loss: 30419.4179 - regularization_loss: 0.0000e+00 - total_loss: 30419.4179\n",
            "Top 3 recommendations for user 42: [b'Rent-a-Kid (1995)' b'Winnie the Pooh and the Blustery Day (1968)'\n",
            " b'Just Cause (1995)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mtiCrvmmBB-"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}